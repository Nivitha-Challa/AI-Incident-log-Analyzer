apiVersion: v1
kind: Namespace
metadata:
  name: incident-analyzer
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-service-config
  namespace: incident-analyzer
data:
  POSTGRES_HOST: "postgres-service"
  POSTGRES_PORT: "5432"
  POSTGRES_DB: "incidents"
  KAFKA_BOOTSTRAP_SERVERS: "kafka-service:9092"
  PROMETHEUS_URL: "http://prometheus-service:9090"
  LOKI_URL: "http://loki-service:3100"
---
apiVersion: v1
kind: Secret
metadata:
  name: ai-service-secrets
  namespace: incident-analyzer
type: Opaque
stringData:
  OPENAI_API_KEY: "your-openai-key-here"
  POSTGRES_PASSWORD: "your-postgres-password"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-service
  namespace: incident-analyzer
  labels:
    app: ai-service
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-service
  template:
    metadata:
      labels:
        app: ai-service
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: ai-service
        image: ai-incident-analyzer/ai-service:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8000
          name: http
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-service-secrets
              key: OPENAI_API_KEY
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: ai-service-secrets
              key: POSTGRES_PASSWORD
        envFrom:
        - configMapRef:
            name: ai-service-config
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: ai-service
  namespace: incident-analyzer
spec:
  selector:
    app: ai-service
  ports:
  - port: 8000
    targetPort: 8000
    name: http
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  namespace: incident-analyzer
spec:
  replicas: 2
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: api-gateway
        image: ai-incident-analyzer/api-gateway:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
        env:
        - name: AI_SERVICE_URL
          value: "http://ai-service:8000"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: ai-service-secrets
              key: POSTGRES_PASSWORD
        envFrom:
        - configMapRef:
            name: ai-service-config
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: api-gateway
  namespace: incident-analyzer
spec:
  selector:
    app: api-gateway
  ports:
  - port: 8080
    targetPort: 8080
  type: LoadBalancer
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: log-processor
  namespace: incident-analyzer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: log-processor
  template:
    metadata:
      labels:
        app: log-processor
    spec:
      containers:
      - name: log-processor
        image: ai-incident-analyzer/log-processor:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "kafka-service:9092"
        - name: AI_SERVICE_URL
          value: "http://ai-service:8000"
        - name: LOKI_URL
          value: "http://loki-service:3100"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alert-receiver
  namespace: incident-analyzer
spec:
  replicas: 2
  selector:
    matchLabels:
      app: alert-receiver
  template:
    metadata:
      labels:
        app: alert-receiver
    spec:
      containers:
      - name: alert-receiver
        image: ai-incident-analyzer/alert-receiver:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8090
        env:
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "kafka-service:9092"
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "250m"
---
apiVersion: v1
kind: Service
metadata:
  name: alert-receiver
  namespace: incident-analyzer
spec:
  selector:
    app: alert-receiver
  ports:
  - port: 8090
    targetPort: 8090
  type: ClusterIP
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: incident-analyzer-ingress
  namespace: incident-analyzer
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: incidents.example.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: api-gateway
            port:
              number: 8080
      - path: /alerts
        pathType: Prefix
        backend:
          service:
            name: alert-receiver
            port:
              number: 8090
