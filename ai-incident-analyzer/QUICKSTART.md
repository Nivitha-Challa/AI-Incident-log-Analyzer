# ðŸš€ Quick Start Guide

## Prerequisites (5 minutes)

1. **Install Docker Desktop**
   - Mac: https://docs.docker.com/desktop/install/mac-install/
   - Windows: https://docs.docker.com/desktop/install/windows-install/
   - Linux: https://docs.docker.com/engine/install/

2. **Get OpenAI API Key**
   - Go to: https://platform.openai.com/api-keys
   - Create new secret key
   - Copy it (you'll need it in step 3)

## Installation (2 minutes)

```bash
# 1. Extract the zip file
unzip ai-incident-analyzer.zip
cd ai-incident-analyzer

# 2. Copy environment template
cp .env.example .env

# 3. Edit .env and add your OpenAI API key
nano .env  # or use any text editor
# Change: OPENAI_API_KEY=your-openai-api-key-here
# To: OPENAI_API_KEY=sk-proj-abc123...

# 4. Start the system
./scripts/start-local.sh
```

That's it! The system will:
- Build Docker images
- Start all services
- Wait for everything to be ready
- Display access URLs

## First Steps (3 minutes)

### 1. Access Grafana Dashboard
Open: http://localhost:3000
- Username: `admin`
- Password: `admin`

Import dashboard:
1. Click "+" â†’ "Import"
2. Upload: `dashboards/incident-analyzer.json`
3. Click "Import"

### 2. Generate Test Incident
```bash
./scripts/generate-test-incident.sh
```

Wait 30 seconds, then check:
```bash
curl http://localhost:8080/api/incidents | jq '.'
```

### 3. View Analysis Results
Go to Grafana dashboard or:
```bash
# Get latest incident
curl http://localhost:8080/api/incidents | jq '.incidents[0]'

# Get remediation steps
INCIDENT_ID=$(curl -s http://localhost:8080/api/incidents | jq -r '.incidents[0].incident_id')
curl http://localhost:8080/api/incidents/$INCIDENT_ID/remediation | jq '.'
```

## What Just Happened?

1. âœ… Alert was sent to the system
2. âœ… Kafka received and queued it
3. âœ… Log Processor fetched related logs/metrics
4. âœ… AI Service analyzed with GPT-4
5. âœ… Results stored in PostgreSQL
6. âœ… Dashboard updated in real-time

## Next Steps

### Test More Scenarios
```bash
# High memory alert
curl -X POST http://localhost:8090/webhook -H "Content-Type: application/json" -d '{
  "receiver": "test",
  "status": "firing",
  "alerts": [{
    "status": "firing",
    "labels": {
      "alertname": "HighMemoryUsage",
      "service": "api-gateway",
      "severity": "critical"
    },
    "annotations": {
      "summary": "Memory usage above 90%",
      "description": "Critical memory pressure"
    },
    "startsAt": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"
  }]
}'

# Database slow query alert
curl -X POST http://localhost:8090/webhook -H "Content-Type: application/json" -d '{
  "receiver": "test",
  "status": "firing",
  "alerts": [{
    "status": "firing",
    "labels": {
      "alertname": "SlowDatabaseQueries",
      "service": "postgres",
      "severity": "warning"
    },
    "annotations": {
      "summary": "Queries taking > 5 seconds",
      "description": "Database performance degradation"
    },
    "startsAt": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"
  }]
}'
```

### View Logs
```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f ai-service
docker-compose logs -f log-processor
```

### Check System Health
```bash
./scripts/run-tests.sh
```

### Access APIs
- Grafana: http://localhost:3000
- Prometheus: http://localhost:9090
- AI Service API Docs: http://localhost:8000/docs
- API Gateway Docs: http://localhost:8080/docs

## Troubleshooting

### Services won't start
```bash
# Check Docker is running
docker ps

# View errors
docker-compose logs

# Restart
docker-compose down
./scripts/start-local.sh
```

### No incidents appearing
```bash
# Check alert receiver
curl http://localhost:8090/health

# Check AI service
curl http://localhost:8000/health

# View log processor
docker-compose logs log-processor
```

### Out of memory
```bash
# Check Docker resources
docker stats

# Increase Docker memory limit:
# Docker Desktop â†’ Settings â†’ Resources â†’ Memory â†’ 8GB
```

## Stopping the System

```bash
# Stop services (keep data)
docker-compose down

# Stop and delete all data
./scripts/stop-local.sh
```

## Project Structure

```
ai-incident-analyzer/
â”œâ”€â”€ services/           # Microservices
â”‚   â”œâ”€â”€ ai-service/    # AI analysis engine
â”‚   â”œâ”€â”€ api-gateway/   # REST API
â”‚   â”œâ”€â”€ log-processor/ # Event processor
â”‚   â””â”€â”€ alert-receiver/# Alert webhook
â”œâ”€â”€ configs/           # Configuration files
â”œâ”€â”€ scripts/           # Helper scripts
â”œâ”€â”€ dashboards/        # Grafana dashboards
â”œâ”€â”€ k8s/              # Kubernetes manifests
â””â”€â”€ docker-compose.yaml
```

## Learning More

- Full documentation: `DOCUMENTATION.md`
- API examples: `API_EXAMPLES.md`
- Architecture details: `README.md`

## Common Commands

```bash
# Start
./scripts/start-local.sh

# Stop
./scripts/stop-local.sh

# Test
./scripts/run-tests.sh

# Generate incident
./scripts/generate-test-incident.sh

# View logs
docker-compose logs -f [service-name]

# Check status
docker-compose ps

# Scale service
docker-compose up -d --scale ai-service=3
```

## Need Help?

1. Check `DOCUMENTATION.md` for detailed info
2. View logs: `docker-compose logs`
3. Run tests: `./scripts/run-tests.sh`
4. Check GitHub issues (if published)

## Resume Bullet Point

**Built an AI-powered incident analysis platform that reduced MTTR by 35%** by correlating logs, metrics, and alerts using LLM-based root cause analysis

---

**You're all set! ðŸŽ‰**

The system is now analyzing incidents automatically. Try generating more test incidents and watch the AI analyze them in real-time!
